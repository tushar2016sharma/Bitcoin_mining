---
title: "Environmental Impacts of Bitcoin Mining"
author: "Tushar Sharma, Kusum Sai Chowdary, Brian Kim"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

**Abstract-** This research project comprehensively analyzes the environmental consequences of Bitcoin mining through traditional machine learning approach. The study focuses on two primary objectives which are referred to as SMART (Specific Measurable Attainable Relevant and Timely) questions: 1)  Based on the historical market conditions and other important predictors, we will predict the Bitcoin price and the transaction volume. 2) We will predict the carbon dioxide emission which will provide insights about the carbon footprint of Bitcoin mining.

```{r}
library(caret)
library(zoo)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(gridExtra)
library(randomForest)
library(xgboost)
```

```{r}
#bitcoin_data <- read.csv("/Users/kusumsaichowdary/Downloads/bitcoin_mining.csv")
# bitcoin_data <- read.csv("C:\\Users\\tusha\\Downloads\\bitcoin_mining.csv")
bitcoin_data <- read.csv("/Users/brian/Downloads/GWU/2023 Fall/Data Science/Project2/bitcoin_mining.csv")

```

```{r}
# Create a vector with names for all columns
new_column_names <- c("Date.and.Time",
  "power_max", "power_min", "power_guess",
  "ann_consumption_max", "ann_consumption_min", "ann_consumption_guess",
  "LB_efficiency", "Est_efficiency", "UB_efficiency",
  "Hydro_MtCO2e", "Est_MtCO2e", "Coal_MtCO2e", "CO2_emission",
  "Hash_rate", "Price", "Volume", "Date"
)

# Rename the columns
colnames(bitcoin_data) <- new_column_names
```

## Introduction

In the world of finance and investment, Bitcoin has emerged as a transformative digital cryptocurrency, revolutionizing traditional economic paradigms and offering a decentralized alternative for transactions. The foundation of Bitcoin mining lies in the ingenious “proof of work” (PoW) algorithm, a complex mechanism designed to validate transactions and secure the network. Miners face the formidable challenge of discovering a specific nonce, a seemingly random number that, when combined with the block’s contents, produces a hash value that adheres to predefined criteria. This process necessitates substantial computational power and operates through trial and error, with miners employing specialized hardware, including Application-Specific Integrated Circuits (ASICs) and Graphics Processing Units (GPUs), meticulously engineered for efficient PoW calculations. While Bitcoin mining plays a vital role in upholding network security and trust, it also carries a significant environmental cost. The surging energy consumption of Bitcoin mining, exacerbated by its rapid expansion, has raised concerns about its contribution to greenhouse gas emissions and global climate change. These concerns necessitate a thorough analysis of the intricate relationship between Bitcoin mining and the environmental impacts. The inception of blockchain technology can be attributed to Bitcoin, which marked the initial and successful endeavor to authenticate transactions using a decentralized data protocol. Engaging in the validation of these transactions demands specific hardware and substantial energy usage, resulting in a substantial carbon footprint [1].

The evolution of the field of Bitcoin mining and its environmental consequences mirrors the dynamic growth and transformation of the broader cryptocurrency ecosystem. In the early days of Bitcoin, mining was a relatively obscure and niche activity, with a limited number of enthusiasts participating in the network. Miners often operated on personal computers, and the energy footprint was minimal. However, as Bitcoin’s value surged and its popularity grew, the landscape of mining underwent a profound shift. With the advent of ASICs and more specialized hardware, miners gained a substantial edge in terms of computational power and efficiency. This development paved the way for large-scale mining operations and industrial mining farms. Consequently, the energy consumption associated with Bitcoin mining skyrocketed, resulting in increased scrutiny and environmental concerns. Based on our 2017 estimates, Bitcoin’s energy consumption was on par with that of Angola or Panama, which were ranked 102nd and 103rd in terms of total energy consumption. To put it in perspective, Bitcoin used about 948 MW, equivalent to 8.3 billion kWh annually [2].

The environmental consequences of Bitcoin mining have become a central topic of debate and research within the cryptocurrency space. As Bitcoin’s market capitalization continued to rise, so did its energy consumption. This evolution prompted researchers to explore the environmental impact more deeply and assess the sustainability of the PoW consensus mechanism. As Bitcoin’s environmental impact has garnered greater attention, it has also sparked discussions about potential solutions and alternatives. Innovations like proof-of-stake (PoS) and other consensus mechanisms designed to be more energy-efficient have gained traction in the cryptocurrency community. Researchers and industry stakeholders are actively exploring how to mitigate the environmental consequences of Bitcoin mining while preserving the network’s security and integrity.

This research project aims to contribute to this evolving field by understanding Bitcoin mining activity through a machine learning predictive approach and exploring its environmental consequences in order to inform policies and industry practices. The paper is organized into three main sections: The first section provides an overview of the data used in the study and basic Exploratory Data Analysis (EDA). The second section discusses the results of the predictions of Bitcoin price and carbon dioxide emission in two ways- without and with the inclusion of lag features. The final section offers conclusions drawn from the findings.

## Methodology

#### A. Bitcoin price and CO2 emissions

```{r}
# Convert date format
bitcoin_data$Date <- as.Date(bitcoin_data$Date, format = "%m/%d/%Y")

# Create Bitcoin price plot
bitcoin_plot <- ggplot(bitcoin_data, aes(Date, Price)) + 
  geom_line(col = 'blue') + 
  labs(title = 'Bitcoin Price', x = 'Year') +
  scale_y_continuous(
    name = "BTC_Price",
    breaks = c(0, 5000, 10000, 15000, 25000, 35000, 45000, 55000, 65000), 
    labels = c('$0', '$5,000', '$10,000', '$15,000', '$25,000','$35,000','$45,000','$55,000','$65,000')
  )

# Create Hashrate plot
Est_MtCO2e_plot <- ggplot(bitcoin_data, aes(Date, Est_MtCO2e)) + 
  geom_line(col = 'blue') + 
  labs(title = 'Est_MtCO2e', x = 'Year') +
  scale_y_continuous(
    name = "Est_MtCO2e",
    sec.axis = sec_axis(trans = ~ . * 1, 
                        breaks = c(50000, 100000, 150000),
                        labels = c('50k', '100k', '150k'))
  )

combined_plot <- plot_grid(bitcoin_plot, Est_MtCO2e_plot, align = "v", ncol = 1)

# Display the combined plot
print(combined_plot)

```


#### B. Stationarity


```{r, fig.height = 6, fig.width = 10, fig.align = 'center', fig.cap = '**Fig. 2. Rolling mean and standard deviation of the features.**'}
# Create a DataFrame from the loaded data
#bitcoin_mining <- read.csv("/Users/kusumsaichowdary/Downloads/bitcoin_mining.csv")
# bitcoin_mining <- read.csv("C:\\Users\\tusha\\Downloads\\bitcoin_mining.csv")
bitcoin_mining <- read.csv("/Users/brian/Downloads/GWU/2023 Fall/Data Science/Project2/bitcoin_mining.csv")


bitcoin_mining <- data.frame(bitcoin_mining)
dim(bitcoin_mining)

# Select specific columns and removed 
data <- subset(
  bitcoin_mining, select = c(
  "Date.and.Time", "power.GUESS..GW", "annualised.consumption.GUESS..TWh",   "Estimated.efficiency..J.Th", "Hydro.only..MtCO2e", "Estimated..MtCO2e",  "Coal.only..MtCO2e", "Emission.intensity..gCO2e.kWh", "Hash.rate.MH.s"
  )
)

start_date <- as.Date("2010-07-18")
end_date <- as.Date("2023-09-22")

data_frame <- data.frame(Date = seq.Date(start_date, end_date, by = "weeks"))

interval_weeks <- 104  # 2 years (approx 104 weeks)
plot_list <- list()

rename <- c("Power guess", "Ann. consumption guess", "Est. efficiency", "Hydro-only MtCO2eq", "Estimated MtCO2eq", "Coal-only MtCO2eq", "Emission intensity", "Hash rate")

for (col_name in columns_to_plot) {
  ts_data <- ts(bitcoin_mining[[col_name]], frequency = 365)

  rolling_data <- data.frame(Date = as.Date(character(0)), RollingMean = numeric(0), RollingSD = numeric(0))

  for (i in seq(start_date, end_date, by = paste(interval_weeks / 52, "years"))) {
    interval_start <- i
    interval_end <- i + 2 * 365  # 2 years in days

    subset_data <- data_frame %>%
      filter(Date >= interval_start, Date < interval_end)

    mean_value <- mean(ts_data[subset_data$Date - start_date + 1])
    sd_value <- sd(ts_data[subset_data$Date - start_date + 1])

    rolling_data <- rbind(rolling_data, data.frame(Date = interval_start + 365, RollingMean = mean_value, RollingSD = sd_value))
  }

  rolling_data$Date <- as.Date(rolling_data$Date)

  plot_data <- rolling_data %>%
    filter(!is.na(RollingMean) & !is.na(RollingSD))

  plot <- ggplot(plot_data, aes(x = Date)) +
    geom_point(aes(y = RollingMean), color = "blue", size = 2) +
    geom_line(aes(y = RollingMean), color = "blue", size = 1) +
    geom_point(aes(y = RollingSD), color = "red", size = 2) +
    geom_line(aes(y = RollingSD), color = "red", size = 1) +
    labs(x = "Date", y = paste("Rolling Mean/SD of", rename[which(columns_to_plot == col_name)])) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),  
          axis.text.y = element_text(size = 8),  
          axis.title.x = element_text(size = 8),  
          axis.title.y = element_text(size = 8)) +
    scale_x_date(date_labels = "%Y", date_breaks = "2 years")

  plot_list[[col_name]] <- plot
}

grid.arrange(grobs = plot_list, ncol = 4, width = 14 * 4, height = 7 * ceiling(length(columns_to_plot) / 4))
```


#### C. Time series cross validation 

Instead of using a regular train-test data split or a regular k-fold cross validation, a rolling window approach or nested cross validation has been employed due to the sequential and temporal nature of the data. Specifically, the script establishes a series of temporal folds, each encompassing testing data of 363 days, against a substantial training set size of 3000 days. In each subsequent fold, the testing data from the previous fold is being added until all the data has been exhausted. 

Fig. 3 shows five distinct cross-validation folds, each divided into training and test segments—the training segment is illustrated with a blue line, while the test segment is depicted in red. This clear segmentation is indicative of the model's training phase on historical data (blue) before being subjected to the prediction phase (red), providing a pragmatic framework to evaluate the model's predictive accuracy on data it has not previously encountered.


```{r, fig.height = 8, fig.width = 6, fig.align = 'center', fig.cap = '**Fig. 3. Time series cross validation folds for Bitcoin price.**'}

bitcoin_data$Date.and.Time <- as.Date(bitcoin_data$Date.and.Time)

# Sort data by 'Date.and.Time'
bitcoin_data <- bitcoin_data[order(bitcoin_data$Date.and.Time), ]

# Function to plot training and test sets
plot_train_test <- function(train_data, test_data, title) {
  ggplot() +
    geom_line(data = train_data, aes(x = Date.and.Time, y = Price), color = "blue", size = 1) +
    geom_line(data = test_data, aes(x = Date.and.Time, y = Price), color = "red", size = 1) +
    labs(title = title, x = "Date", y = "Price") +
    theme_minimal()
}

# Manual time series cross-validation
fold_size <- 363
training_size <- 3000
num_folds <- floor((nrow(bitcoin_data) - training_size) / fold_size) # better to have floor division

# Generate subplots for each fold
plots <- lapply(1 : num_folds, function(i) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1

  train_data <- bitcoin_data[1 : (start_idx + training_size - 1), ]  # Update training set
  test_data <- bitcoin_data[(start_idx + training_size) : end_idx, ]

  title <- paste("Fold", i)
  plot_train_test(train_data, test_data, title) +
    xlim(range(bitcoin_data$Date.and.Time))  # Set x-axis limit for the entire date range
}) 

# Combine plots into a single facet_wrap

multiplot <- do.call(grid.arrange, c(plots, ncol = 1))

# Apply theme settings
multiplot <- multiplot +
  theme(
    axis.text = element_text(size = 14, face = 'bold'),      
    axis.title = element_text(size = 14, face = 'bold'),     
    plot.title = element_text(size = 14, face = 'bold'),
    legend.text = element_text(size = 12),               
    legend.title = element_text(size = 12)
  )
```

## Results

#### A. Bitcoin price prediction

The evaluation of a Random Forest model applied to Bitcoin price prediction is presented, illustrating the model's varying degree of success across different temporal segments. The graph in the study delineates a comparison of actual and predicted Bitcoin prices, with the model achieving an average Mean Absolute Percentage Error (MAPE) of 26.57, indicating a moderate prediction accuracy, and an average Mean Squared Prediction Error (MSPE) of 12.88, reflecting the variance of the predictions from the actual values. Notably, the model's Akaike Information Criterion (AIC) averages at 34613.21, serving as a gauge for the model's relative quality. The predictive trajectory closely mirrors the actual price movements, though it struggles with the market's pronounced peaks and troughs, underscoring the inherent volatility and unpredictability of cryptocurrency markets.

A detailed cross-validation, represented in the accompanying table, reveals that the model's performance fluctuates across folds; Fold 3 exhibits the highest MAPE, indicating lower predictive accuracy, whereas Fold 5 boasts the lowest MAPE and AIC, suggesting a superior model fit and predictive precision for that segment. These variations underscore the challenges in forecasting financial time series data, where external factors often induce significant predictive discrepancies.

```{r}
# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
  return(errors)
}

# Function to perform random forest regression and calculate errors
perform_rf <- function(train_data, test_data) {
  # Input features
  train_feat <- c("power_max","Hash_rate", "Volume")
  
  # Train random forest model
  rf_model <- randomForest(Price ~ ., data = train_data[, c(train_feat, "Price")])
  
  # Predict on test data
  test_data$predicted <- predict(rf_model, newdata = test_data)
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Price, test_data$predicted, rf_model)
  
  return(list(
    predictions = data.frame(
      Date.and.Time = test_data$Date.and.Time,
      Actual = test_data$Price,
      Predicted = test_data$predicted
    ),
    errors = errors,
    model = rf_model
  ))
}

# List to store actual vs predicted results and errors for each fold
rf_results_list <- list()

# Manual time series cross-validation
for (i in 1 : num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1:(start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size) : end_idx, ]
  
  # Perform random forest regression
  results <- perform_rf(train_data, test_data)
  
  # Store results in the list
  rf_results_list[[paste("Fold", i)]] <- results
}

# Calculate averages of MAPE, MSPE, and AIC across all folds
average_errors <- calculate_errors(
  actual = do.call(rbind, lapply(rf_results_list, function(x) x$predictions$Actual)),
  predicted = do.call(rbind, lapply(rf_results_list, function(x) x$predictions$Predicted)),
  model = rf_results_list[[1]]$model  # Assuming all models are the same across folds
)

# Combine plots into a single time series plot
rf_combined_plot <- ggplot() +
  geom_line(data = do.call(rbind, lapply(seq_along(rf_results_list), function(i) {
    results <- rf_results_list[[i]]
    results$predictions$Fold <- paste("Fold", i)
    return(results$predictions)
  })),
  aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1, linetype = "solid") +
  geom_line(data = do.call(rbind, lapply(seq_along(rf_results_list), function(i) {
    results <- rf_results_list[[i]]
    results$predictions$Fold <- paste("Fold", i)
    return(results$predictions)
  })),
  aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  labs(title = paste("Random forest - Avg MAPE:", round(average_errors$MAPE, 2),
                    ",", "Avg MSPE:", round(average_errors$MSPE, 2),
                    ",", "Avg AIC:", round(average_errors$AIC, 2)),
       x = "Date", y = "Price") +
  theme_minimal() +
    theme(
      axis.text = element_text(size = 14, face = 'bold'),      
      axis.title = element_text(size = 14, face = 'bold'),     
      plot.title = element_text(size = 15, face = 'bold'),
      legend.text = element_text(size = 14),               
      legend.title = element_text(size = 14) 
    ) +
  scale_linetype_manual(values = rep("solid", num_folds))

# Save the combined plot as an object
rf_combined_plot <- ggplotGrob(rf_combined_plot)
```

The XG Boost model applied to Bitcoin price predictions indicate that the model has a close following of the actual price movements, denoted by the red line, with its predictions. The model records an average Mean Absolute Percentage Error (MAPE) of 25.99, reflecting a moderate level of accuracy in its predictions. The Mean Squared Prediction Error (MSPE) stands at 12.68, which points to the model's ability to predict with a reasonable degree of precision, and the average Akaike Information Criterion (AIC) is 34660.88, suggesting the model's goodness of fit to the data.

The table provides a breakdown of performance metrics across five different folds, with Fold 3 showing a notably higher MAPE, indicating that the predictions for this particular fold were less precise relative to the actual values. In contrast, Fold 5 demonstrates the lowest MAPE and a relatively lower AIC, indicating a more accurate set of predictions and a better fit model for the data within this fold.

The results reflect the model's challenge in capturing the extreme peaks and troughs of the Bitcoin price, a common difficulty in the volatile cryptocurrency market. These findings emphasize the complexities of financial time series forecasting and the need for robust modeling techniques to handle the unpredictable nature of such data.

```{r}
# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
}

# Function to perform XGBoost regression and calculate errors
perform_xgb <- function(train_data, test_data, fold_number) {
  # Specify XGBoost parameters
  params <- list(
    objective = "reg:squarederror"
  )
  
  # Train the XGBoost model
  train_feat <- c("power_max","Hash_rate", "Volume")
  
  xgb_model <- xgboost(
    data = as.matrix(train_data[, train_feat]),  # Exclude Date.and.Time
    label = train_data$Price,
    params = params,
    nrounds = 500,
    verbose = 0  # Suppress printing of train-rmse
  )
  
  # Make predictions on the test set
  predictions <- predict(xgb_model, as.matrix(test_data[, train_feat]))
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Price, predictions, xgb_model)
  
  # Store results without printing
  results <- data.frame(
    Date.and.Time = test_data$Date.and.Time,
    Actual = test_data$Price,
    Predicted = predictions,
    MAPE = errors$MAPE,
    MSPE = errors$MSPE,
    AIC = errors$AIC,  # Add AIC to the results
    Fold = paste("Fold", fold_number)
  )
}

# List to store actual vs predicted results and errors for each fold
xg_results_list <- list()

# Manual time series cross-validation
for (i in 1 : num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1 : (start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size) : end_idx, ]
  
  # Perform XGBoost regression
  results <- perform_xgb(train_data, test_data, i)
  
  # Store results in the list
  xg_results_list[[paste("Fold", i)]] <- results
}

# Combine actual and predicted values from all folds
combined_data <- bind_rows(xg_results_list)

# Calculate averages of MAPE, MSPE, and AIC across all folds
average_errors <- calculate_errors(
  actual = combined_data$Actual,
  predicted = combined_data$Predicted,
  model = xg_results_list[[1]]$model  # Assuming all models are the same across folds
)

fold_boundaries <- rep(seq(1, num_folds - 1), each = training_size - 1) * fold_size

# Combine plots into a single time series plot
xg_combined_plot <- ggplot() +
  geom_line(data = combined_data,
            aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1, linetype = "solid") +
  geom_line(data = combined_data,
            aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  labs(title = paste("XGBoost - Avg MAPE:", round(average_errors$MAPE, 2),
                    ",", "Avg MSPE:", round(average_errors$MSPE, 2),
                    ",", "Avg AIC:", round(average_errors$AIC, 2)),
       x = "Date", y = "Price") +
  theme_minimal() + 
  theme(
    axis.text = element_text(size = 14, face = 'bold'),      
    axis.title = element_text(size = 14, face = 'bold'),     
    plot.title = element_text(size = 15, face = 'bold'),
    legend.text = element_text(size = 14),               
    legend.title = element_text(size = 14) 
  ) +
  scale_linetype_manual(values = rep("solid", num_folds)) 

# Save the combined plot as an object
xg_combined_plot <- ggplotGrob(xg_combined_plot)
```

```{r, fig.width = 16, fig.height = 4, fig.align = 'center', fig.cap = '**Fig 4. Prediction of Bitcoin price by Random forest (left) and XGBoost regression (right) on the 5 cross folds combined.**'}

# Combine the price prediction plots side by side
grid.arrange(rf_combined_plot, xg_combined_plot, ncol = 2)
```

In the construction of the time series predictive model for Bitcoin pricing, the introduction of lagged features constitutes a critical enhancement to the analytical framework. Specifically, a lagged feature was generated by shifting the price data by one day, thus creating a new column Lag_1d in the dataset. This methodological step is imperative for encapsulating the temporal autocorrelation characteristic of financial time series, where previous values bear predictive power over future values.


Subsequent to the introduction of Lag_1d, the dataset was purged of rows containing missing values, which resulted from the lagging process. These missing entries, indicative of initial time points lacking historical data, were removed to preserve the integrity of data. This cleansing step ensures that the model's inputs are devoid of potential biases or errors that could compromise the validity of subsequent predictive insights. 


```{r}
bitcoin_data <- bitcoin_data %>%
  arrange(Date.and.Time) %>%
  mutate(
    Lag_1d = lag(Price, 1)
    #Lag_7d = lag(Price, 7),         # 7 days lag
    #Lag_15d = lag(Price, 15)        # 15 days lag
  )

# Remove rows with NA (which will be the initial rows due to lagging)
bitcoin_data <- na.omit(bitcoin_data)
```

In the assessment of two distinct Random Forest models applied to the task of predicting Bitcoin prices, the incorporation of lagged features has demonstrably enhanced the model's forecasting precision. The initial model, devoid of lagged features, presented a Mean Absolute Percentage Error (MAPE) of 26.57, a Mean Squared Prediction Error (MSPE) of 12.88, and an Akaike Information Criterion (AIC) of 34613.21. These values serve as a baseline against which the performance of subsequent modeling refinements can be measured.

The introduction of lagged features, signifying the inclusion of the previous day's price data in the model, resulted in a notable reduction in all three key performance metrics. The adjusted model exhibited a MAPE of 22.25, a reduction that indicates an enhanced accuracy in the percentage error rate of the predictions. The MSPE decreased to 10.86, suggesting a tighter clustering of the model's price forecasts around the actual observed values. Most telling was the reduction in AIC to 27784.42, implying a substantially improved fit of the model to the historical price data.

This comparative analysis substantiates the premise that temporal dynamics, captured through lagged features, are essential for the accurate modeling of financial time series. By leveraging the previous day's price data, the model gains critical insights into the immediate trends and fluctuations within the market, thereby refining its predictive capability. The discernible improvements across all metrics reinforce the methodological value of incorporating lagged features into the model, validating their role in achieving a more profound and accurate forecast of Bitcoin prices.


```{r}
# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
}

# Function to perform random forest regression with lagged features and calculate errors
perform_rf_lagged <- function(train_data, test_data) {
  #train_feat <- c("power_max","Hash_rate", "Volume", "Lag_7d", "Lag_15d")
  train_feat <- c("power_max","Hash_rate", "Volume", "Lag_1d")
  
  # Train random forest model
  rf_model_lagged <- randomForest(Price ~ ., data = train_data[, c(train_feat, "Price")])
  
  # Predict on test data
  test_data$predicted <- predict(rf_model_lagged, newdata = test_data[, train_feat])
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Price, test_data$predicted, rf_model_lagged)
  
  return(list(
    predictions = data.frame(
      Date.and.Time = test_data$Date.and.Time,
      Actual = test_data$Price,
      Predicted = test_data$predicted
    ),
    errors = errors,
    model = rf_model_lagged  # Store the model in the results
  ))
}

# List to store actual vs predicted results and errors for each fold (Random Forest)
rf_results_list_lagged <- list()

# Manual time series cross-validation for Random Forest with Lagged Features
for (i in 1 : num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1 : (start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size):end_idx, ]
  
  # Perform random forest regression with lagged features
  results <- perform_rf_lagged(train_data, test_data)
  
  # Store results in the list
  rf_results_list_lagged[[paste("Fold", i)]] <- results
}

# Calculate averages of MAPE, MSPE, and AIC across all folds for Random Forest with Lagged Features
rf_average_errors_lagged <- calculate_errors(
  actual = do.call(rbind, lapply(rf_results_list_lagged, function(x) x$predictions$Actual)),
  predicted = do.call(rbind, lapply(rf_results_list_lagged, function(x) x$predictions$Predicted)),
  model = rf_results_list_lagged[[1]]$model  # Assuming all models are the same across folds
)

# Extract predictions from the list of results
rf_combined_data_lagged <- do.call(rbind, lapply(seq_along(rf_results_list_lagged), function(i) {
  fold_data <- rf_results_list_lagged[[i]]$predictions
  fold_data$Fold <- paste("Fold", i)
  return(fold_data)
}))

fold_boundaries <- seq(training_size, length.out = num_folds, by = fold_size)

# Create combined plot for Random Forest with Lagged Features
rf_combined_plot_lagged <- ggplot(rf_combined_data_lagged) +
  geom_line(aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  labs(title = paste("Random Forest - Avg MAPE:",
                     round(rf_average_errors_lagged$MAPE, 2),
                     ",", "Avg MSPE:", round(rf_average_errors_lagged$MSPE, 2),
                     ",", "Avg AIC:", round(rf_average_errors_lagged$AIC, 2)),
       x = "Date", y = "Price", "") +
  theme_minimal() + 
  theme(
    axis.text = element_text(size = 14, face = 'bold'),      
    axis.title = element_text(size = 14, face = 'bold'),     
    plot.title = element_text(size = 15, face = 'bold'),
    legend.text = element_text(size = 14),               
    legend.title = element_text(size = 14) 
  ) +
  geom_vline(data = data.frame(xintercept = fold_boundaries), aes(xintercept = xintercept),
             linetype = "dashed", color = "black", size = 0.5)

# Save the combined plot as an object
rf_combined_plot_lagged <- ggplotGrob(rf_combined_plot_lagged)
```

Building on the earlier findings with the Random Forest model, the application of XGBoost to Bitcoin price prediction further underscores the significance of lagged features in time series forecasting. The comparative analysis reveals a stark contrast in the performance of the XGBoost model before and after the inclusion of lagged features. Initially, the XGBoost model—absent of these temporal indicators—reported a Mean Absolute Percentage Error (MAPE) of 25.99, a Mean Squared Prediction Error (MSPE) of 12.68, and an Akaike Information Criterion (AIC) of 34660.88, setting the stage for subsequent enhancement.

The integration of lagged features into the XGBoost model marks a pivotal improvement. The MAPE sees a dramatic reduction to 13.61, indicating a notable decrease in the percentage error of predictions. The MSPE follows suit, plummeting to 6.73, which signifies a greatly improved precision in forecasting the variance of Bitcoin prices. Additionally, the model's AIC drops to 27334.89, reflecting a refined model fit that better captures the complexities of the data.

This progression from the Random Forest to the XGBoost model, with the strategic incorporation of lagged features, demonstrates a consistent theme: temporal data points are invaluable for enhancing the accuracy and reliability of predictive models in financial time series. By effectively leveraging the information embedded in the preceding time steps, both models achieve a deeper level of analytical rigor, yielding forecasts that are not only more aligned with the actual market movements but also provide a stronger basis for decision-making in the volatile cryptocurrency domain.


```{r}
# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
}

# Function to train XGBoost model with lagged features and make predictions
train_and_predict_xgb_lagged <- function(train_data, test_data) {
  #train_feat <- c("power_max","Hash_rate", "Volume", "Lag_7d", "Lag_15d")
  train_feat <- c("power_max","Hash_rate", "Volume", "Lag_1d")
  
  # Specify XGBoost parameters
  params <- list(
    objective = "reg:squarederror"
  )
  
  # Train the XGBoost model using lagged features
  xgb_model_lagged <- xgboost(
    data = as.matrix(train_data[, train_feat]),  # Exclude Date.and.Time
    label = train_data$Price,
    params = params,
    nrounds = 500,
    verbose = 0
  )
  
  # Make predictions on the test set using the same lagged features
  predictions <- predict(xgb_model_lagged, as.matrix(test_data[, train_feat]))
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Price, predictions, xgb_model_lagged)
  
  # Store results and return
  results <- data.frame(
    Date.and.Time = test_data$Date.and.Time,
    Actual = test_data$Price,
    Predicted = predictions,
    MAPE = errors$MAPE,
    MSPE = errors$MSPE,
    AIC = errors$AIC  # Add AIC to the results
  )
}

# List to store actual vs predicted results and errors for each fold (XGBoost with Lagged Features)
xgb_results_list_lagged <- list()

# Manual time series cross-validation for XGBoost with Lagged Features
for (i in 1:num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1:(start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size):end_idx, ]
  
  # Train XGBoost model with lagged features and make predictions
  results <- train_and_predict_xgb_lagged(train_data, test_data)
  
  # Store results in the list
  xgb_results_list_lagged[[paste("Fold", i)]] <- results
}

# Calculate averages of MAPE, MSPE, and AIC across all folds for XGBoost with Lagged Features
xgb_average_errors_lagged <- calculate_errors(
  actual = do.call(rbind, lapply(xgb_results_list_lagged, function(x) x$Actual)),
  predicted = do.call(rbind, lapply(xgb_results_list_lagged, function(x) x$Predicted)),
  model = xgb_results_list_lagged[[1]]$model  # Assuming all models are the same across folds
)

# Print average errors for XGBoost with Lagged Features
#print(xgb_average_errors_lagged)

# Prepare data for combined plot (XGBoost with Lagged Features)
xgb_combined_data_lagged <- do.call(rbind, lapply(seq_along(xgb_results_list_lagged), function(i) {
  fold_data <- xgb_results_list_lagged[[i]]
  fold_data$Fold <- paste("Fold", i)
  return(fold_data)
}))

# Create combined plot for XGBoost with Lagged Features
xg_combined_plot_lagged <- ggplot(xgb_combined_data_lagged) +
  geom_line(aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  labs(title = paste("XGBoost - Avg MAPE:",
                    round(xgb_average_errors_lagged$MAPE, 2),
                    ",", "Avg MSPE:", round(xgb_average_errors_lagged$MSPE, 2),
                    ",", "Avg AIC:", round(xgb_average_errors_lagged$AIC, 2)),
       x = "Date", y = "Price") +
  theme_minimal() + 
  theme(
    axis.text = element_text(size = 14, face = 'bold'),      
    axis.title = element_text(size = 14, face = 'bold'),     
    plot.title = element_text(size = 15, face = 'bold'),
    legend.text = element_text(size = 14),               
    legend.title = element_text(size = 14) 
  ) 

# Save the combined plot as an object
xg_combined_plot_lagged <- ggplotGrob(xg_combined_plot_lagged)
```

```{r, fig.width = 16, fig.height = 4, fig.align = 'center', fig.cap = '**Fig 5. Prediction of Bitcoin price by Random forest (left) and XGBoost regression (right) with 1-day lag feature on the 5 cross folds combined.**'}

# Combine the price prediction plots with lag feature side by side
grid.arrange(rf_combined_plot_lagged, xg_combined_plot_lagged, ncol = 2)
```

#### B. CO2 emission prediction

The Random Forest and XGBoost models were applied to estimate the carbon emissions from Bitcoin mining, using a robust cross-validation method. The performance metrics across five folds highlighted significant variability, with the Random Forest model exhibiting a MAPE range from 2.58 to 25.11 and MSPE from 0.16 to 7.38. The AIC scores varied from 49.405 to 1658.34, suggesting sensitivity to the data segment being trained on. Notably, Fold 1 of the Random Forest model achieved the lowest MAPE and MSPE, indicating the most accurate predictions for that data subset. Conversely, Fold 2 showed the highest errors, pointing to the least accurate predictions.

The initial Random Forest model, which did not incorporate lag features, yielded a MAPE of 10.53, an MSPE of 2.19, and an AIC of 6483.71. This model's predictions, while moderately accurate, were outperformed by the enhanced model that included lag feature as shown in Fig. 7. Incorporating lag features into the Random Forest model resulted in significant improvements, with a reduced MAPE of 8, MSPE of 1.61, and a notably lower AIC of 5071.91. This affirmed the importance of past values as significant predictors for future trends in carbon emissions related to Bitcoin mining. Incorporating lag features into the Random Forest model resulted in significant improvements, with a reduced MAPE of 8, MSPE of 1.61, and a notably lower AIC of 5071.91. This affirmed the importance of past values as significant predictors for future trends in carbon emissions related to Bitcoin mining.

When comparing the two models with the inclusion of lag features, the Random Forest model demonstrated superior performance over the XGBoost model, particularly in terms of MAPE and AIC. The improved accuracy and parsimony suggest that the Random Forest model, with its lagged data inputs, is more adept at capturing the structure of the carbon emissions data, leading to more precise forecasts. However, it is important to note that performing more hyperparameter tuning could yield an XGBoost model which is better than random forest. 

In conclusion, for the objective of estimating carbon emissions from Bitcoin mining, both models successfully predict the carbon dioxide emissions by Bitcoin mining activity although with the choosen parameters, the random forest model slightly outperforms the XGBoost model. 


```{r}

# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
}

# Function to perform random forest regression and calculate errors
perform_rf <- function(train_data, test_data) {
  # Input features
  train_feat <- c('Coal_MtCO2e')
  
  # Train random forest model
  rf_model <- randomForest(Est_MtCO2e ~ ., data = train_data[, c(train_feat, "Est_MtCO2e")])
  
  # Predict on test data
  test_data$predicted <- predict(rf_model, newdata = test_data)
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Est_MtCO2e, test_data$predicted, rf_model)
  
  return(list(
    predictions = data.frame(
      Date.and.Time = test_data$Date.and.Time,
      Actual = test_data$Est_MtCO2e,
      Predicted = test_data$predicted
    ),
    errors = errors,
    model = rf_model
  ))
}

# List to store actual vs predicted results and errors for each fold
rf_results_list <- list()

# Manual time series cross-validation
for (i in 1 : num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1:(start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size) : end_idx, ]
  
  # Perform random forest regression
  results <- perform_rf(train_data, test_data)
  
  # Store results in the list
  rf_results_list[[paste("Fold", i)]] <- results
}

# Calculate averages of MAPE, MSPE, and AIC across all folds
average_errors <- calculate_errors(
  actual = do.call(rbind, lapply(rf_results_list, function(x) x$predictions$Actual)),
  predicted = do.call(rbind, lapply(rf_results_list, function(x) x$predictions$Predicted)),
  model = rf_results_list[[1]]$model  # Assuming all models are the same across folds
)

# Combine plots into a single time series plot
rf_co2_combined_plot <- ggplot() +
  geom_line(data = do.call(rbind, lapply(seq_along(rf_results_list), function(i) {
    results <- rf_results_list[[i]]
    results$predictions$Fold <- paste("Fold", i)
    return(results$predictions)
  })),
  aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1, linetype = "solid") +
  geom_line(data = do.call(rbind, lapply(seq_along(rf_results_list), function(i) {
    results <- rf_results_list[[i]]
    results$predictions$Fold <- paste("Fold", i)
    return(results$predictions)
  })),
  aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  labs(title = paste("Random forest - Avg MAPE:", round(average_errors$MAPE, 2),
                    ",", "Avg MSPE:", round(average_errors$MSPE, 2),
                    ",", "Avg AIC:", round(average_errors$AIC, 2)),
       x = "Date", y = "Estimated MtCO2eq") +
  theme_minimal() +
    theme(
      axis.text = element_text(size = 14, face = 'bold'),      
      axis.title = element_text(size = 14, face = 'bold'),     
      plot.title = element_text(size = 15, face = 'bold'),
      legend.text = element_text(size = 14),               
      legend.title = element_text(size = 14) 
    ) +
  scale_linetype_manual(values = rep("solid", num_folds))

# Save the combined plot as an object
rf_co2_combined_plot <- ggplotGrob(rf_co2_combined_plot)
```



```{r}

# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
}

# Function to perform XGBoost regression and calculate errors
perform_xgb <- function(train_data, test_data, fold_number) {
  # Specify XGBoost parameters
  params <- list(
    objective = "reg:squarederror"
  )
  
  # Train the XGBoost model
  train_feat <- c('Coal_MtCO2e')
  
  xgb_model <- xgboost(
    data = as.matrix(train_data[, train_feat]),  # Exclude Date.and.Time
    label = train_data$Est_MtCO2e,
    params = params,
    nrounds = 500,
    verbose = 0  # Suppress printing of train-rmse
  )
  
  # Make predictions on the test set
  predictions <- predict(xgb_model, as.matrix(test_data[, train_feat]))
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Est_MtCO2e, predictions, xgb_model)
  
  # Store results without printing
  results <- data.frame(
    Date.and.Time = test_data$Date.and.Time,
    Actual = test_data$Est_MtCO2e,
    Predicted = predictions,
    MAPE = errors$MAPE,
    MSPE = errors$MSPE,
    AIC = errors$AIC,  # Add AIC to the results
    Fold = paste("Fold", fold_number)
  )
}

# List to store actual vs predicted results and errors for each fold
xg_results_list <- list()

# Manual time series cross-validation
for (i in 1 : num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1 : (start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size) : end_idx, ]
  
  # Perform XGBoost regression
  results <- perform_xgb(train_data, test_data, i)
  
  # Store results in the list
  xg_results_list[[paste("Fold", i)]] <- results
}

# Combine actual and predicted values from all folds
combined_data <- bind_rows(xg_results_list)

# Calculate averages of MAPE, MSPE, and AIC across all folds
average_errors <- calculate_errors(
  actual = combined_data$Actual,
  predicted = combined_data$Predicted,
  model = xg_results_list[[1]]$model  # Assuming all models are the same across folds
)

fold_boundaries <- rep(seq(1, num_folds - 1), each = training_size - 1) * fold_size

# Combine plots into a single time series plot
xg_co2_combined_plot <- ggplot() +
  geom_line(data = combined_data,
            aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1, linetype = "solid") +
  geom_line(data = combined_data,
            aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  scale_y_continuous(limits = c(15, 70)) +
  labs(title = paste("XGBoost - Avg MAPE:", round(average_errors$MAPE, 2),
                    ",", "Avg MSPE:", round(average_errors$MSPE, 2),
                    ",", "Avg AIC:", round(average_errors$AIC, 2)),
       x = "Date", y = "Estimated MtCO2eq") +
  theme_minimal() + 
  theme(
    axis.text = element_text(size = 14, face = 'bold'),      
    axis.title = element_text(size = 14, face = 'bold'),     
    plot.title = element_text(size = 15, face = 'bold'),
    legend.text = element_text(size = 14),               
    legend.title = element_text(size = 14) 
  ) +
  scale_linetype_manual(values = rep("solid", num_folds)) 

# Save the combined plot as an object
xg_co2_combined_plot <- ggplotGrob(xg_co2_combined_plot)
```


```{r, fig.width = 16, fig.height = 4, fig.align = 'center', fig.cap = '**Fig 6. Prediction of CO2 emission by Random forest (left) and XGBoost regression (right) on the 5 cross folds combined.**'}

# Combine the price prediction plots side by side
grid.arrange(rf_co2_combined_plot, xg_co2_combined_plot, ncol = 2)
```


```{r}
bitcoin_data <- bitcoin_data %>%
  arrange(Date.and.Time) %>%
  mutate(
    Lag_1d = lag(Est_MtCO2e, 1)           # 1 day lag
    #Lag_7d = lag(Est_MtCO2e, 7),         # 7 days lag
    #Lag_15d = lag(Est_MtCO2e, 15)        # 15 days lag
  )

# Remove rows with NA (which will be the initial rows due to lagging)
bitcoin_data <- na.omit(bitcoin_data)
```

```{r}
# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
}

# Function to perform random forest regression with lagged features and calculate errors
perform_rf_lagged <- function(train_data, test_data) {
  #train_feat <- c("Coal_MtCO2e", "Lag_7d", "Lag_15d")
  train_feat <- c("Coal_MtCO2e", "Lag_1d")
  
  # Train random forest model
  rf_model_lagged <- randomForest(Est_MtCO2e ~ ., data = train_data[, c(train_feat, "Est_MtCO2e")])
  
  # Predict on test data
  test_data$predicted <- predict(rf_model_lagged, newdata = test_data[, train_feat])
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Est_MtCO2e, test_data$predicted, rf_model_lagged)
  
  return(list(
    predictions = data.frame(
      Date.and.Time = test_data$Date.and.Time,
      Actual = test_data$Est_MtCO2e,
      Predicted = test_data$predicted
    ),
    errors = errors,
    model = rf_model_lagged  # Store the model in the results
  ))
}

# List to store actual vs predicted results and errors for each fold (Random Forest)
rf_results_list_lagged <- list()

# Manual time series cross-validation for Random Forest with Lagged Features
for (i in 1 : num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1 : (start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size):end_idx, ]
  
  # Perform random forest regression with lagged features
  results <- perform_rf_lagged(train_data, test_data)
  
  # Store results in the list
  rf_results_list_lagged[[paste("Fold", i)]] <- results
}

# Calculate averages of MAPE, MSPE, and AIC across all folds for Random Forest with Lagged Features
rf_average_errors_lagged <- calculate_errors(
  actual = do.call(rbind, lapply(rf_results_list_lagged, function(x) x$predictions$Actual)),
  predicted = do.call(rbind, lapply(rf_results_list_lagged, function(x) x$predictions$Predicted)),
  model = rf_results_list_lagged[[1]]$model  # Assuming all models are the same across folds
)

# Extract predictions from the list of results
rf_combined_data_lagged <- do.call(rbind, lapply(seq_along(rf_results_list_lagged), function(i) {
  fold_data <- rf_results_list_lagged[[i]]$predictions
  fold_data$Fold <- paste("Fold", i)
  return(fold_data)
}))

fold_boundaries <- seq(training_size, length.out = num_folds, by = fold_size)

# Create combined plot for Random Forest with Lagged Features
rf_co2_combined_plot_lagged <- ggplot(rf_combined_data_lagged) +
  geom_line(aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  labs(title = paste("Random Forest - Avg MAPE:",
                     round(rf_average_errors_lagged$MAPE, 2),
                     ",", "Avg MSPE:", round(rf_average_errors_lagged$MSPE, 2),
                     ",", "Avg AIC:", round(rf_average_errors_lagged$AIC, 2)),
       x = "Date", y = "Estimated MtCO2e", "") +
  theme_minimal() + 
  theme(
    axis.text = element_text(size = 14, face = 'bold'),      
    axis.title = element_text(size = 14, face = 'bold'),     
    plot.title = element_text(size = 15, face = 'bold'),
    legend.text = element_text(size = 14),               
    legend.title = element_text(size = 14) 
  ) +
  geom_vline(data = data.frame(xintercept = fold_boundaries), aes(xintercept = xintercept),
             linetype = "dashed", color = "black", size = 0.5)

# Save the combined plot as an object
rf_co2_combined_plot_lagged <- ggplotGrob(rf_co2_combined_plot_lagged)
```

```{r}
# Function to calculate MAPE, MSPE, and AIC
calculate_errors <- function(actual, predicted, model) {
  # Exclude rows with missing values
  valid_rows <- complete.cases(actual, predicted)
  actual <- actual[valid_rows]
  predicted <- predicted[valid_rows]

  # Calculate MAPE and MSPE
  mape <- mean(abs((actual - predicted) / actual)) * 100
  mspe <- mean(((actual - predicted) / actual)^2) * 100

  # Calculate AIC
  residuals <- actual - predicted
  n <- length(actual)
  k <- length(model$coef) - 1  # Number of coefficients, excluding intercept
  aic <- n * log(sum(residuals^2) / n) + 2 * k

  errors <- data.frame(
    MAPE = mape,
    MSPE = mspe,
    AIC = aic
  )
}

# Function to train XGBoost model with lagged features and make predictions
train_and_predict_xgb_lagged <- function(train_data, test_data) {
  #train_feat <- c('Coal_MtCO2e', "Lag_7d", "Lag_15d")
  train_feat <- c("Coal_MtCO2e", "Lag_1d")
  
  # Specify XGBoost parameters
  params <- list(
    objective = "reg:squarederror"
  )
  
  # Train the XGBoost model using lagged features
  xgb_model_lagged <- xgboost(
    data = as.matrix(train_data[, train_feat]),  # Exclude Date.and.Time
    label = train_data$Est_MtCO2e,
    params = params,
    nrounds = 500,
    verbose = 0
  )
  
  # Make predictions on the test set using the same lagged features
  predictions <- predict(xgb_model_lagged, as.matrix(test_data[, train_feat]))
  
  # Calculate MAPE, MSPE, and AIC
  errors <- calculate_errors(test_data$Est_MtCO2e, predictions, xgb_model_lagged)
  
  # Store results and return
  results <- data.frame(
    Date.and.Time = test_data$Date.and.Time,
    Actual = test_data$Est_MtCO2e,
    Predicted = predictions,
    MAPE = errors$MAPE,
    MSPE = errors$MSPE,
    AIC = errors$AIC  # Add AIC to the results
  )
}

# List to store actual vs predicted results and errors for each fold (XGBoost with Lagged Features)
xgb_results_list_lagged <- list()

# Manual time series cross-validation for XGBoost with Lagged Features
for (i in 1:num_folds) {
  start_idx <- (i - 1) * fold_size + 1
  end_idx <- start_idx + fold_size + training_size - 1
  
  # Split data into training and testing sets
  train_data <- bitcoin_data[1:(start_idx + training_size - 1), ]
  test_data <- bitcoin_data[(start_idx + training_size):end_idx, ]
  
  # Train XGBoost model with lagged features and make predictions
  results <- train_and_predict_xgb_lagged(train_data, test_data)
  
  # Store results in the list
  xgb_results_list_lagged[[paste("Fold", i)]] <- results
}

# Calculate averages of MAPE, MSPE, and AIC across all folds for XGBoost with Lagged Features
xgb_average_errors_lagged <- calculate_errors(
  actual = do.call(rbind, lapply(xgb_results_list_lagged, function(x) x$Actual)),
  predicted = do.call(rbind, lapply(xgb_results_list_lagged, function(x) x$Predicted)),
  model = xgb_results_list_lagged[[1]]$model  # Assuming all models are the same across folds
)

# Print average errors for XGBoost with Lagged Features
print(xgb_average_errors_lagged)

# Prepare data for combined plot (XGBoost with Lagged Features)
xgb_combined_data_lagged <- do.call(rbind, lapply(seq_along(xgb_results_list_lagged), function(i) {
  fold_data <- xgb_results_list_lagged[[i]]
  fold_data$Fold <- paste("Fold", i)
  return(fold_data)
}))

# Create combined plot for XGBoost with Lagged Features
xg_co2_combined_plot_lagged <- ggplot(xgb_combined_data_lagged) +
  geom_line(aes(x = Date.and.Time, y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(x = Date.and.Time, y = Predicted, color = "Predicted", linetype = "solid"), size = 1) +
  labs(title = paste("XGBoost - Avg MAPE:",
                    round(xgb_average_errors_lagged$MAPE, 2),
                    ",", "Avg MSPE:", round(xgb_average_errors_lagged$MSPE, 2),
                    ",", "Avg AIC:", round(xgb_average_errors_lagged$AIC, 2)),
       x = "Date", y = "Estimated MtCO2eq") +
  theme_minimal() + 
  theme(
    axis.text = element_text(size = 14, face = 'bold'),      
    axis.title = element_text(size = 14, face = 'bold'),     
    plot.title = element_text(size = 15, face = 'bold'),
    legend.text = element_text(size = 14),               
    legend.title = element_text(size = 14) 
  ) +
  scale_y_continuous(limit = c(15, 70))

# Save the combined plot as an object
xg_co2_combined_plot_lagged <- ggplotGrob(xg_co2_combined_plot_lagged)
```

```{r, fig.width = 16, fig.height = 4, fig.align = 'center', fig.cap = '**Fig 7. Prediction of CO2 emission by Random forest (left) and XGBoost regression (right) with 1-day lag feature on the 5 cross folds combined.**'}

# Combine the price prediction plots side by side
grid.arrange(rf_co2_combined_plot_lagged, xg_co2_combined_plot_lagged, ncol = 2)
```

## Conclusions
Over the past ten years, the value of Bitcoin has generally been on the rise. Predictive models based on machine learning have proven to be quite useful in estimating its future value. Likewise, the projected levels of carbon dioxide emissions have displayed a trend that appears to align with that of Bitcoin's value, with a Pearson correlation coefficient of approximately 0.84, indicating a strong association between the two. This indicates that with the application of advanced modeling techniques, it might be possible to precisely predict key factors related to the process of Bitcoin mining.

For Bitcoin price prediction, the XG Boost model with lagged features outperforms the Random Forest model, achieving a superior predictive accuracy and model fit. For estimating CO2 emissions from Bitcoin mining, the Random Forest model with lagged features emerges as more effective, leveraging historical data for more accurate and reliable predictions.

In summary, lagged features play a pivotal role in improving the predictive performance of machine learning models in time series analysis of Bitcoin data. The Random Forest model, when equipped with these lagged features, provides the most accurate predictions for CO2 emissions from Bitcoin mining. However, the XG Boost model shows the best results for Bitcoin price prediction when these temporal dynamics are considered. These findings underscore the importance of considering historical data points and the intrinsic temporal dependencies in financial time series forecasting.

## References
1) Calvo-Pardo, H. F., Mancini, T., & Olmo, J. (2022). Machine Learning the Carbon Footprint of Bitcoin Mining. Journal of Risk and Financial Management, 15(2), 71. https://doi.org/10.3390/jrfm15020071

2) J. T. Aparicio, M. Romao and C. J. Costa, "Predicting Bitcoin prices : The effect of interest rate, search on the internet, and energy prices," 2022 17th Iberian Conference on Information Systems and Technologies (CISTI), Madrid, Spain, 2022, pp. 1-5, doi: 10.23919/CISTI54924.2022.9820085.

3) A. P. Ratto, S. Merello, L. Oneto, Y. Ma, L. Malandri and E. Cambria, "Ensemble of Technical Analysis and Machine Learning for Market Trend Prediction," 2018 IEEE Symposium Series on Computational Intelligence (SSCI), Bangalore, India, 2018, pp. 2090-2096, doi: 10.1109/SSCI.2018.8628795.

4) Cambridge Bitcoin Electricity Consumption Index 2023.
https://ccaf.io/cbnsi/cbeci

5) Bitcoin Network Hash Rate, NASDAQ 2023. https://data.nasdaq.com/data/BCHAIN/HRATE-bitcoin-hash-rate

6) Bitcoin’s price and volume data from data.bitcoinity.org,
https://data.bitcoinity.org/markets/price_volume/all/USD?t=lb&vu=curr. 
 





